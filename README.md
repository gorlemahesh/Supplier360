# Supplier360 â€“ AI-Powered Supplier Risk & Compliance Assistant

Supplier360 is an end-to-end **AI + AWS Bedrockâ€“powered Supplier 360Â° view** that helps procurement and risk teams:

- Evaluate **supplier compliance** against internal policies  
- Detect **duplicate / overlapping suppliers**  
- Monitor **performance & risk signals** over time  

It uses **Amazon Bedrock Agents** with custom **Lambda-based action groups** and an **Aurora PostgreSQL** database, with a simple **Streamlit UI** for local demos.

---

## 1. Key Features

- ğŸ¤– **Bedrock Agentâ€“driven workflow**  
  Natural language questions like _â€œGive me the compliance health score for Supplier Xâ€_ or  
  _â€œShow high-risk suppliers by regionâ€_.

- ğŸ“Š **Compliance scoring engine**  
  Lambda functions query Aurora and compute **compliance health scores** based on rules and weights.

- ğŸ§¹ **Supplier deduplication**  
  Identify suppliers that may be duplicates (similar names, tax IDs, locations, etc).

- ğŸ“ˆ **Performance insights**  
  Aggregate metrics (on-time delivery, quality issues, etc.) exposed through the Agent.

- ğŸ–¥ï¸ **Local Streamlit UI**  
  Simple chat-style UI to talk to the Bedrock Agent and view responses, perfect for demos.

---

## 2. High-Level Architecture

**Core flow (for a typical query):**

1. User opens the **Streamlit UI** and asks a question  
   â†’ e.g., â€œWhat is the compliance health report for Supplier A?â€

2. Streamlit calls **Amazon Bedrock Agent Runtime** â†’ `InvokeAgent`.

3. The **Bedrock Agent** decides which **Action Group** to call:
   - `compliance` (compliance health, risk score)
   - `deduplication` (duplicate supplier detection)
   - `performance` (supplier performance metrics)

4. The selected **Lambda function** (one per action group) runs:
   - Uses shared helpers from `backend/common`  
   - Connects to **Aurora PostgreSQL (RDS)**  
   - Runs SQL queries  
   - Computes scores / aggregates  
   - Returns structured JSON back to the Agent

5. The **Agent** formats a natural language response and returns it to the **Streamlit UI**.

> Note: For the demo, the **UI is hosted locally**, while AWS resources (Bedrock, Lambda, Aurora) run in the cloud.

---

## 3. Repository Structure

```text
.
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md                # (This file)
â”œâ”€â”€ agent
â”‚   â”œâ”€â”€ action-groups
â”‚   â”‚   â”œâ”€â”€ compliance.yaml  # Bedrock action group definition â€“ compliance
â”‚   â”‚   â”œâ”€â”€ deduplication.yaml
â”‚   â”‚   â””â”€â”€ performance.yaml
â”‚   â””â”€â”€ prompts
â”‚       â””â”€â”€ system_prompt.md # System prompt and instructions for the Agent
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ common
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bedrock_utils.py # (If used) Shared utilities for Bedrock / parsing
â”‚   â”‚   â””â”€â”€ rds_client.py    # Helper to connect to Aurora / Postgres
â”‚   â””â”€â”€ lambdas
â”‚       â”œâ”€â”€ compliance
â”‚       â”‚   â””â”€â”€ lambda_function.py
â”‚       â”œâ”€â”€ deduplication
â”‚       â”‚   â””â”€â”€ lambda_function.py
â”‚       â””â”€â”€ performance
â”‚           â””â”€â”€ lambda_function.py
â”œâ”€â”€ db
â”‚   â”œâ”€â”€ data
â”‚   â”‚   â””â”€â”€ data.sql         # Sample / synthetic supplier data
â”‚   â””â”€â”€ schema
â”‚       â””â”€â”€ schema.sql       # Aurora / Postgres DDL (tables, indexes, etc.)
â”œâ”€â”€ docs
â”‚   â””â”€â”€ architecture-overview.md  # High-level design & diagrams
â””â”€â”€ frontend
    â””â”€â”€ streamlit_app
        â”œâ”€â”€ README.md
        â”œâ”€â”€ app.py           # Streamlit UI (chat with Bedrock Agent)
        â””â”€â”€ requirements.txt # Python dependencies for the UI
```
---
## 4. Tech Stack

### ğŸ§  AI & Agent Framework
- **Amazon Bedrock Agents**
- **Bedrock Agent Runtime (InvokeAgent)**
- **YAML Action Groups** mapped to Lambda functions
- **System Prompt** defining agent rules and reasoning

### ğŸ–¥ï¸ Backend (Serverless)
- **AWS Lambda (Python 3.x)** for compliance, deduplication, and performance logic
- **Amazon Aurora PostgreSQL (RDS)** for supplier master data and scoring data
- **VPC + Private Subnets** for secure database connectivity
- **IAM Roles & Policies** enabling:
  - Lambda â†’ RDS connectivity  
  - Bedrock Agent â†’ Lambda invocation  
  - CloudWatch logging  

### ğŸ—„ï¸ Database Layer
- **Aurora PostgreSQL**
- Includes:
  - `db/schema/schema.sql` â€” table definitions and indexes  
  - `db/data/data.sql` â€” synthetic sample dataset for demo  

### ğŸ“¦ Python Shared Utilities (Backend)
Located under `backend/common/`:
- `rds_client.py` â€” PostgreSQL database connector  
- `bedrock_utils.py` â€” common utilities for formatting or Bedrock operations  

### ğŸ–¼ï¸ Frontend (Local Demo)
- **Streamlit** UI (`frontend/streamlit_app/app.py`)
- Integrates with Bedrock Agent Runtime via `boto3`
- Chat-based interface for interacting with the Supplier360 agent

### ğŸ“¦ Frontend Dependencies
---
- streamlit
- boto3
- botocore
- python-dotenv
---

## 5. Prerequisites

Before running or deploying Supplier360, ensure the following setup and tools are available.

### ğŸ” AWS Requirements
- Active **AWS Account**
- **Amazon Bedrock** access enabled (Agents + Runtime)
- **AWS Lambda** service available
- **Amazon Aurora PostgreSQL** cluster created
- IAM permissions allowing:
  - Bedrock Agent â†’ invoke Lambda  
  - Lambda â†’ connect to Aurora RDS  
  - Lambda â†’ write logs to CloudWatch  

### ğŸ—„ï¸ Database Requirements
- Aurora PostgreSQL instance with:
  - Host / Endpoint  
  - Port (default: 5432)  
  - Username & Password  
  - Database name (recommended: `supplier360`)  

- Apply database schema and Load synthetic dataset:
  ```bash
  psql -h <RDS_ENDPOINT> -U <USER> -d <DB_NAME> -f db/schema/schema.sql
  psql -h <RDS_ENDPOINT> -U <USER> -d <DB_NAME> -f db/data/data.sql
  ```
  
### ğŸ Local Machine Requirements:
 -  Python 3.9 or higher
 - Package manager:
 - pip or
 - conda or
 - virtualenv
 - Ability to run Streamlit:
 ```bash
      streamlit run app.py
 ```

